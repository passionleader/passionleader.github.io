---
# 속성은 대쉬 내부에 작성하세요

# 영문으로 같은 내용 작성 시 id 같아야 함
lng_pair: id_kakao_linux7
# 영문으로 작성하는 경우 영문제목
title: (Linux)스토리지 관리

# 저자 설정(생략 가능)
#author: initializer

# 카테고리와 태그 설정
category: 카카오클라우드스쿨
tags: [Linux, RAID]

# 섬네일 이미지
img: "https://bloximages.newyork1.vip.townnews.com/redandblack.com/content/tncms/assets/v3/editorial/4/59/45940eb2-5403-11e9-a843-db0e4491cc90/5ca13d8453042.image.jpg"

# 댓글 비활성화 여부
comments_disable: false

# 작성 날짜
date: 2022-07-21 10:18:51 +0900

# image_lazy_loader_posts = false 혹은 image_viewer_posts = false인 경우에만 사용하세요
#image_viewer_on: true
#image_lazy_loader_on: true

# 블로그내 검색 혹은 검색 엔진 검색에서 예외할건가
#on_site_search_exclude: true
#search_engine_exclude: true

# to disable this page, simply set published: false or delete this file
#published: false
---

<!-- outline-start -->

[카카오 클라우드 스쿨] 클라우드 스토리지, 스토리지 마운트, RAID에 대해 알아 본다

<!-- outline-end -->

## 클라우드 상에서의 스토리지
* 클라우드 스토리지의 종류
* ![img_34](https://user-images.githubusercontent.com/104918800/181285792-c5774153-9055-4235-a3f6-21237d2c6e08.jpg)
* 클라우드 상에서 필요한 노드들
* ![img_35](https://user-images.githubusercontent.com/104918800/181285794-b9a6c936-e916-4387-b025-3aae02575cb0.jpg)

<br>
<hr>

## 디스크 마운트

* 리눅스의 물리장치는 논리장치(디렉터리)와 연계된 상태로 쓸 수 있다
* 외부에 있는 스토리지에서 볼륨을 마운트하여 사용하면 vda(virtual disk)로 나타나기도 함
* VMWare에 CD/DVD 디스크를 추가한 후 마운트 해 보자

<br>

* 마운트
  * mount /dev/sr0 /test
* 마운트 해제 (둘 중 어느 곳을 써도 됨)
  * umount /test
  * umount /dev/sr0

<br>

* **1. 현재 DVD 장치가 마운트 된 곳을 확인해 보기**

```shell
[root@srv7 0721]# mount | grep sr0
/dev/sr0 on /run/media/root/CentOS 7 x86_64 type iso9660 (ro,nosuid,nodev,relatime,uid=0,gid=0,iocharset=utf8,dmode=0500,mode=0400,uhelper=udisks2)
```

* 위 명령어로 마운트가 된 위치를 알 수 있음
  * 여기서 /dev/sr0: 리눅스의 ODD(cd-dvd롬) 물리장치를 의미함
  * /run/media... : 마운트가 된 위치를 의미함


<br>

**2.장치가 잘 마운트 되어 있는지 마운트된 위치에서 목록 확인해 보기**

```shell
[root@srv7 0721]# ls /run/media/root/CentOS\ 7\ x86_64/
CentOS_BuildTag  LiveOS
EFI              Packages
EULA             repodata
GPL              RPM-GPG-KEY-CentOS-7
images           RPM-GPG-KEY-CentOS-Testing-7
isolinux         TRANS.TBL
```

<br>

**3. 마운트 해제**

```shell
[root@srv7 0721]# umount /dev/sr0
```

<br>


**4. 다른 위치에 마운트 해보기**

```shell
# 마운트
[root@srv7 ~]# mkdir /test
[root@srv7 ~]# mount /dev/sr0 /test
mount: /dev/sr0 is write-protected, mounting read-only

# 확인해 보기
[root@srv7 ~]# mount | grep /dev/sr0
/dev/sr0 on /test type iso9660 (ro,relatime)
```

<br>

**5. NFS 마운트**

* NFS: 원격에 있는 디렉터리
* nfs는 재부팅하면 마운트가 해제됨
  * 마운트 정보를 지속적으로 마운트 하고 싶다면 /etc/fstab에 기록해두자
  * OS 부팅시 그곳을 읽어들이게 된다

```shell
[root@srv7 ~]# mount -t nfs 1.1.1.1:/remote /test
```

<br>
<hr>

## 효율적인 디스크 관리 (LVM, RAID)

### LVM: Logical Volume Group
* 크키가 제각각인 다수의 볼륨을 연결해서 하나의 볼륨으로 사용할 수 있음
* 또한 이를 다시 논리적으로 나눠서 원하는 크기의 볼륨으로 사용할 수 있음
  * ex) 1+80+19 => 35, 45, 20
  * ![img_29](https://user-images.githubusercontent.com/104918800/181050207-430049f8-c34c-4348-a338-c0d72671826c.jpg)

<br>

* 단점
  * 속도가 느림
  * 데이터 손실 시 복구가 (사실상) 불가능함

* 따라서 fault-tolerance를 지원해야 하는 기술이 필요
  * 결함으로 손실이 발생하더라도 복구가 가능해야 한다(결함 허용이 가능해야 함)
  * => RAID!

<br>

### RAID

* 두개 이상의 디스크를 결합
* 데이터손실을 방지하고 데이터I/O 속도를 높일 수 있음
* 구분
  * 소프트웨어방식: (리눅스 등)운영체제에서 소프트웨어적으로 제공하는 방식
  * 하드웨어방식: 서버/스토리지 자체적으로 제공하는 방식. 더 안정적이고, 속도도 빠름

<br>

* RAID 0 (stripe)
  * 개념: 디스크 여러개에 나누어 쓰기
  * 디스크 공간 활용률: 100%(10 + 10 = 20)
  * 쓰기 속도가 향상된다
  * 그러나 하나라도 날릴 경우 복구X
    * HLO
    * EL <br><br>

* RAID 1 (mirroring)
  * 개념: 데이터를 복제하여 보관한다
  * 디스크 공간활용률: 50% (10 + 10 = 10)
  * Fault tolerance를 지원
  * 안정적인 운영이 가능함(데이터가 손상되지 않는다)
    * HELLO
    * HELLO <br><br>

* RAID 4
  * 개념 3개 정도의 저장용 스토리지 + 1개의 parity 저장 스토리지
    * (parity bit: 복구를 위한 비트, 홀수 및 짝수 비트를 각각 합산한다)
  * 공간활용률: 높음(n-1개)
  * 저장 스토리지가 고장나더라도 parity bit로 복구 가능
  * 하지만 parity 저장 스토리지가 고장날 경우 복구하기 힘듦
    * 1 0
    * ~~0 1~~ 고장난 경우 유추 가능
    * 1 1
    * 1 0 (parity bit) <br><br>

* RAID5
  * RAID4와 유사
  * Parity bit를 각 스토리지에 분산시켜 사용
    * p 1 0
    * 1 p 1
    * 0 0 p <br><br>

* RAID10
  * RAID 1과 0이 혼합된 방식 (뭐가 위로 오든 상관 없음)
  * 쓰기 속도 향상 + 안정성 모두 제공
  * 그러나 비쌈 <br><br>

* 결론
  * RAID를 사용하면 데이터를 안정적으로 관리할 수 있다
  * 또한 쓰기 속도도 향상시킬 수 있다

<br>
<hr>


## 디스크 새로 추가해 보기(실습)

* 로컬 디스크 추가하기
  * 로컬 디스크는 전원을 꺼야 추가 가능
  * 클라우드에서 디스크/랜카드 추가는 전원을 끌 필요가 없음

<br>

**1 . 전원을 종료한다**

<br>

**2 . vmware 에서 디스크 추가한다**
* 볼륨 이름 지정
* ![img_18](https://user-images.githubusercontent.com/104918800/180261274-059fd277-d093-4894-a41c-327f8f3514c6.png)
  * qcow2는 표준 디스크 확장명, vmdk는 vm에서 쓰는 디스크 확장명

<br>

**3 . 새로 추가된 물리장치 확인하기 (sdb는 파티셔닝 되지 않은 상태임)**

```shell
[root@srv7 ~]# ls /dev//sd*
/dev//sda  /dev//sda1  /dev//sda2  /dev//sdb
```

<br>

**4 . 파티셔닝**

* 파티션 타입?
  * primary
    * 데이터 작성 가능 파티션, 최대 4개까지 파티셔닝 가능
    * 첫 번째 파티션에서 부트로더(마스터 부트 레코드), OS 설치가 가능
  * extended
    * 파티션 1 ~ 3번째 파티션에 OS 데이터를 설치한다면
    * 4번째 파티션 내부에 logical partition을 설정해 논리 파티션을 추가적으로 만들 수 있음
    * 즉, 추가적인 파티셔닝 (논리)가 가능함

<br>

* 물리 자원 상태 확인

```shell
[root@srv7 ~]# ls /dev//sd*
/dev//sda  /dev//sda1  /dev//sda2  /dev//sdb

[root@srv7 ~]# fdisk -l

Disk /dev/sdb: 5368 MB, 5368709120 bytes, 10485760 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
...
```

<br>

* 파티셔닝 수행

```shell
\[root@srv7 ~]# fdisk /dev/sdb
Welcome to fdisk (util-linux 2.23.2).

Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.

Device does not contain a recognized partition table
Building a new DOS disklabel with disk identifier 0x6c534233.

Command (m for help): n
Partition type:
   p   primary (0 primary, 0 extended, 4 free)
   e   extended
Select (default p): p
Partition number (1-4, default 1):
First sector (2048-10485759, default 2048):
Using default value 2048
Last sector, +sectors or +size{K,M,G} (2048-10485759, default 10485759):
Using default value 10485759
Partition 1 of type Linux and of size 5 GiB is set

Command (m for help): p

Disk /dev/sdb: 5368 MB, 5368709120 bytes, 10485760 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk label type: dos
Disk identifier: 0x6c534233

   Device Boot      Start         End      Blocks   Id  System
/dev/sdb1            2048    10485759     5241856   83  Linux

Command (m for help): w
The partition table has been altered!

Calling ioctl() to re-read partition table.
Syncing disks.
[root@srv7 ~]# fdisk -l | grep /dev/sdb
Disk /dev/sdb: 5368 MB, 5368709120 bytes, 10485760 sectors
/dev/sdb1            2048    10485759     5241856   83  Linux
```

<br>

**5 . 파일 시스템을 해당 디스크에 적용**

* 파일 시스템
  * ext4: 널리 사용되고 있는 중, 파일 하나당 최대 16TB까지 저장 가능
  * xfs: 파일 하나당 8EB까지 저장 가능

```shell
[root@srv7 ~]# mkfs.ext4 /dev/sdb1
```

<br>

**6 . 마운트**

```shell
[root@srv7 ~]# mkdir /mydata
[root@srv7 ~]# mount /dev/sdb1 /mydata
```

<br>

**7 . 마운트 정보 기록**
* /etc/fstab 에 해당 마운트 정보를 기록
* 재부팅 이후에도 지속적으로 마운트 정보를 유지할 수 있도록 해 줌

```shell
vi /etc/fstab
---
/dev/sdb1               /mydata                 ext4    defaults        0 0
```

<br>

**8 . 재부팅 후 마운트 정보 확인**

```shell
[root@srv7 ~]# df
Filesystem              1K-blocks    Used Available Use% Mounted on
devtmpfs                   914488       0    914488   0% /dev
tmpfs                      931512       0    931512   0% /dev/shm
tmpfs                      931512   10524    920988   2% /run
tmpfs                      931512       0    931512   0% /sys/fs/cgroup
/dev/mapper/centos-root  17811456 5122444  12689012  29% /
/dev/sdb1                 5028480   20472   4729532   1% /mydata
/dev/sda1                 1038336  189004    849332  19% /boot
```

<br>
<hr>


## 로드밸런서, NFS, 마운트 실습
### 실습 환경
* ![img_32](https://user-images.githubusercontent.com/104918800/181285772-6750b8a0-0d4c-479d-a2eb-bf1abafb3fa6.jpg)
* 1번 실습자
  * 2, 3번 사용자의 스토리지로 사용
  * 위에서 만든 디스크를 사용하여 NFS 서버를 구축한다
  * NFS 스토리지에 index.html 파일을 집어 넣는다
  * 주의: 해당 디스크는 2번 3번 실습자 외에는 접근할 수 없어야 함(2, 3만 등록한다) <br><br>
* 2, 3번 실습자
  * HTTPD 서버로 사용
  * 자신의 /var/www/html 폴더에 1번 실습자의 NFS 스토리지를 마운트한다
  * http 서버의 /var/log/httpd/access_log 를 모니터링 한다(tail -3f) <br><br>
* 4번 실습자
  * HA proxy를 구성
  * 로드밸런서 역할

<br>
<hr>

### HA Proxy

* 로드밸런서
  * green/blue Deployment
  * 외부 사용자가 /blue(url)로 접속 시 로드밸런서가 판별
    * 그 주소를 이해하기 위해서는 ALB이어야 함(데이터를 볼 수 있어야)
  * ALB는 blue를 처리하기 위해 해당 서브넷으로 보내고, 해당 서브넷 내부에서 NLB로 연결됨
    * NLB는 트래픽 량에 따라 오토스케일링을 연계할 수 있음

<br>

* haproxy: L4, L7 로드밸런서
* haproxy 구성 예 방법은 하단과 같음
  * 참고 블로그: https://cloudwafer.com/blog/installing-haproxy-on-centos-7/

```bash
global
   log /dev/log local0
   log /dev/log local1 notice
   chroot /var/lib/haproxy
   stats socket /run/haproxy/admin.sock mode 660 level admin
    stats timeout 30s
    user haproxy
    group haproxy
    daemon

defaults
     log global
     mode http
     option httplog
     option dontlognull
     timeout connect 5000
     timeout client 50000
     timeout server 50000

frontend http_front
     bind *:80
     stats uri /haproxy?stats
     default_backend http_back

backend http_back
     balance roundrobin
     server my_server private_IP:80 check
     server my_server private_IP:80 check
```

<br>
<hr>
